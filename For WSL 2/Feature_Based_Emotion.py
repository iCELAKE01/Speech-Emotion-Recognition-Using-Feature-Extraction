# -*- coding: utf-8 -*-
"""SER_Capstone_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfDokb8QUopwIbVnq47RlHZrDWT9_8xg
"""

import librosa
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import load_model
import os # Good practice to import os if dealing with paths

print("TensorFlow version:", tf.__version__)

# --- Define Paths ---
# Using the current working directory for the output file
# You can change this to a full path if needed, e.g., "/home/icelake2/predictions/prediction_result.txt"
output_filename = "/home/icelake2/prediction_result.txt"
model_path = "/home/icelake2/Speech-Emotion-Recognition-Using-Feature-Extraction/trained_model(base).h5"
audio_path = "/home/icelake2/capstone_ASR/recorded_audio.wav"


# --- Load Model ---
print(f"Loading model: {model_path}")
# Consider adding error handling for file not found if needed
model = load_model(model_path)
print("Model loaded.")

# --- Preprocessing Function ---
def preprocess_audio(file_path):
    print(f"Preprocessing: {file_path}")
    # Load the audio file
    audio, sr = librosa.load(file_path, sr=16000)

    # Extract features
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=1)

    # Pad or truncate
    max_len = 162
    mfccs = np.pad(mfccs, ((0, 0), (0, max(0, max_len - mfccs.shape[1]))), mode='constant')
    mfccs = mfccs[:, :max_len] # Shape (1, 162)

    # Transpose and add channel dimension -> (162, 1, 1) ?
    # Assuming model expects (batch, 162, 1) based on prior context, let's re-check this step.
    # User code does: T -> (162, 1) -> expand_dims -> (162, 1, 1)
    # Let's adjust based on typical Keras usage expecting (batch, timesteps, features):
    mfccs = mfccs.T # Shape (162, 1) - Time steps first, features second

    # Add batch dimension -> (1, 162, 1)
    preprocessed = np.expand_dims(mfccs, axis=0)
    print(f"Preprocessing complete. Shape: {preprocessed.shape}") # Should be (1, 162, 1) if model expects (None, 162, 1)
    return preprocessed

# --- Preprocess Audio ---
preprocessed_audio = preprocess_audio(audio_path)

# --- Make Prediction ---
print("Predicting...")
predictions = model.predict(preprocessed_audio)
predicted_class = np.argmax(predictions, axis=1)
# print(f"Predicted class index: {predicted_class[0]}") # Optional: for debugging

# --- Map to Labels ---
emotion_labels = ['neutral', 'calm', 'happy', 'sad', 'angry', 'fearful', 'disgust', 'surprise'] # Ensure this matches training

# --- Prepare Result String ---
if predicted_class[0] < len(emotion_labels):
    predicted_emotion = emotion_labels[predicted_class[0]]
    result_string = f"The User sounds {predicted_emotion}"
else:
    # Handle case where predicted index is out of bounds
    result_string = f"Error: Predicted class index ({predicted_class[0]}) is invalid."
    predicted_emotion = "Error" # Mark as error for potential file writing logic

# --- Print to Console ---
print(result_string)

# --- Store Result in Text File ---
print(f"Attempting to save result to: {output_filename}")
try:
    # 'w' mode overwrites the file each time.
    # Use 'a' mode (append) if you want to add multiple predictions to the same file over time.
    with open(output_filename, 'w') as file_handle:
        # Write the full sentence to the file, adding a newline character at the end
        file_handle.write(result_string + '\n')

        # --- Alternative: Write only the emotion word ---
        # if predicted_emotion != "Error":
        #     file_handle.write(predicted_emotion + '\n')
        # else:
        #     file_handle.write("Prediction Error\n")

    print(f"Successfully saved prediction to {output_filename}")

except IOError as e:
    # Catch potential file writing errors (e.g., permissions)
    print(f"Error: Could not write to file {output_filename}")
    print(e)
except Exception as e:
    # Catch any other unexpected errors during file writing
    print(f"An unexpected error occurred during file writing: {e}")




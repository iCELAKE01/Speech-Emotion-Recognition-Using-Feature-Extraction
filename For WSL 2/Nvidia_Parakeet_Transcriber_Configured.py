# -*- coding: utf-8 -*-
"""Parakeet_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QQHIRVfj2aTCC88alBnzOz-fbUSZRe03
"""

# Cell 2: Import Libraries
import nemo.collections.asr as nemo_asr
import torch
import os
import librosa # Used for audio loading/checking
import numpy as np

print("Libraries imported.")

# Cell 3: Configuration - SET YOUR FILE PATHS HERE!

# <<< --- USER: Define the paths to your model and audio file --- >>>

nemo_file_path = "/home/icelake2/capstone_ASR/parakeet-tdt_ctc-110m.nemo"  # IMPORTANT: Replace with the actual path to your .nemo file
audio_file_path = "/home/icelake2/capstone_ASR/recorded_audio.wav"               # IMPORTANT: Replace with the actual path to your audio file (e.g., .wav)

# <<< --- END USER CONFIGURATION --- >>>

print("--- Configuration ---")
print(f"Model File: {nemo_file_path}")
print(f"Audio File: {audio_file_path}")

# Basic check if files exist
if not os.path.exists(nemo_file_path):
    print(f"ERROR: Model file not found at: {nemo_file_path}")
    # Stop execution if file not found
    raise FileNotFoundError(f"Model file not found at: {nemo_file_path}")
if not os.path.exists(audio_file_path):
    print(f"ERROR: Audio file not found at: {audio_file_path}")
    # Stop execution if file not found
    raise FileNotFoundError(f"Audio file not found at: {audio_file_path}")

print("File paths seem valid.")

# Cell 4: Setup Device (GPU or CPU)

if torch.cuda.is_available():
    device = 'cuda'
    print("\n--- Device Setup ---")
    print("Using GPU for inference.")
    # Optional: print GPU details
    # print(f"GPU Name: {torch.cuda.get_device_name(0)}")
else:
    device = 'cpu'
    print("\n--- Device Setup ---")
    print("Using CPU for inference (this might be significantly slower).")

# Cell 5: Load the ASR Model

print("\n--- Loading Model ---")
print(f"Attempting to load NeMo model from: {nemo_file_path}")
print("This might take a moment...")

try:
    # Use the specific class for Parakeet CTC BPE models based on your filename
    asr_model = nemo_asr.models.EncDecCTCModelBPE.restore_from(
        restore_path=nemo_file_path,
        map_location=torch.device(device)  # Load directly onto the determined device
    )
    asr_model.eval() # Set model to evaluation mode (disables dropout, etc.)
    print("Model loaded successfully onto device:", device)
except Exception as e:
     print(f"\nERROR: Failed to load the model.")
     print(f"Tried using class 'EncDecCTCModelBPE'. Ensure this is the correct class for '{os.path.basename(nemo_file_path)}'.")
     print(f"Check NeMo documentation or model source if unsure.")
     print(f"Original error details: {e}")
     # Stop execution by re-raising the exception
     raise e

# Cell 6: Optional Audio Check (Verify Sample Rate)
# Most ASR models expect a specific sample rate, often 16000 Hz.
# This cell checks your audio file's sample rate.

try:
    print("\n--- Audio File Check ---")
    signal, sr = librosa.load(audio_file_path, sr=None) # sr=None loads the original sample rate
    print(f"Detected sample rate: {sr} Hz")
    target_sr = 16000 # Common target sample rate for ASR models
    if sr != target_sr:
        print(f"WARNING: Model likely expects {target_sr} Hz audio, but found {sr} Hz.")
        print("Transcription quality might be affected.")
        # If needed, you could resample here using:
        # signal_resampled = librosa.resample(y=signal, orig_sr=sr, target_sr=target_sr)
        # And then save the resampled signal to a temporary file before transcription.
        # This example proceeds without resampling.
    else:
        print(f"Sample rate matches the common target ({target_sr} Hz).")
except Exception as e:
    print(f"Could not check audio file properties using librosa: {e}")
    print("Ensure 'librosa' is installed if you want this check.")
    print("Proceeding with transcription anyway...")

# Cell 6: Load and Prepare Audio Data
# This model likely expects audio data directly, not just the path.
# We will load the audio and ensure it's at the target sample rate (16kHz).

TARGET_SR = 16000 # Standard sample rate for many ASR models

print("\n--- Loading and Preparing Audio ---")
print(f"Loading audio file: {audio_file_path}")

try:
    # Load audio using librosa, resampling directly to TARGET_SR if necessary
    signal, sr = librosa.load(audio_file_path, sr=TARGET_SR)
    print(f"Audio loaded successfully. Sample rate: {sr} Hz")
    print(f"Signal shape: {signal.shape}, Duration: {len(signal)/sr:.2f} seconds")

    # Check if signal is loaded correctly (it should be a NumPy array)
    if not isinstance(signal, np.ndarray):
         raise TypeError("librosa.load did not return a NumPy array.")
    if len(signal) == 0:
         raise ValueError("Loaded audio signal is empty.")

except Exception as e:
    print(f"\nERROR: Failed to load or process audio file: {audio_file_path}")
    print(f"{e}")
    print("Ensure 'librosa' and potentially 'soundfile'/'ffmpeg' are installed and the audio file is valid.")
    # Stop execution if audio loading fails
    raise e

# Cell 7: Transcribe the Audio Data

print("\n--- Transcription ---")
print(f"Starting transcription using the loaded audio data...")

# Make sure the 'signal' variable from Cell 6 is available here
if 'signal' not in locals():
     raise NameError("The 'signal' variable (audio data) was not found. Ensure Cell 6 ran successfully.")

try:
    # *** CHANGE THIS LINE ***
    # Pass the loaded audio data (as a list containing the NumPy array)
    # using the 'audio' keyword argument.
    transcriptions = asr_model.transcribe(
        audio=[signal], # Pass the loaded NumPy array in a list
        batch_size=1
    )
    # *** END CHANGE ***

    print("Transcription complete.")

    # Cell 8 logic (displaying results) remains the same
    print("\n--- Result ---")
    if transcriptions and isinstance(transcriptions[0], list) and len(transcriptions[0]) > 0:
        if hasattr(transcriptions[0][0], "text"):
            print("Transcription:")
            print(transcriptions[0][0].text)  # Extracting text from the Hypothesis object
        else:
            print("Unexpected transcription output format.")
    elif transcriptions and isinstance(transcriptions[0], str):
        print("Transcription:")
        print(transcriptions[0])
    else:
        print("Transcription resulted in empty or unexpected output format.")
        print(f"Raw output: {transcriptions}")



except Exception as e:
    print(f"\nERROR: An error occurred during transcription:")
    print(f"{e}")
    # Add a check specific to this method
    print("\nCheck if the model's 'transcribe' method expects the 'audio' keyword with pre-loaded data.")
    print("\nOther Troubleshooting tips:")
    print("- Ensure the audio file was loaded correctly in the previous step (check logs).")
    print("- Check available system memory (RAM) and GPU memory (VRAM) if applicable.")

# Cell: Extract and Print Only the Transcription Text

if isinstance(transcriptions, list) and len(transcriptions) > 0:
    first_item = transcriptions[0]

    if isinstance(first_item, list) and len(first_item) > 0:
        hypothesis = first_item[0]

        if hasattr(hypothesis, "text"):
            print(hypothesis.text)  # Extracting text from Hypothesis object
        else:
            print("Error: 'text' attribute not found in hypothesis object.")

    elif isinstance(first_item, dict) and "text" in first_item:
        print(first_item["text"])  # If it's a dictionary, extract the 'text' field

    elif isinstance(first_item, str):
        print(first_item)  # If it's already a string, print it directly

    else:
        print("Error: Unexpected transcription format.", transcriptions)
else:
    print("Error: Transcription output is empty or invalid.")

import re
import os

# Define the save path
save_path = "/home/icelake2/capstone_ASR/transcription_output.txt"

# Raw output from transcription
raw_output = str(transcriptions)  # Convert to string if not already

# Extract text content using regex
match = re.search(r"text='(.*?)'", raw_output)

if match:
    extracted_text = match.group(1)  # Extract the text
    print(extracted_text)  # Print to confirm

    # Ensure the directory exists
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    # Save to the specified path
    with open(save_path, "w", encoding="utf-8") as file:
        file.write(extracted_text)

    print(f"Saved transcription to {save_path}")
else:
    print("Error: Could not extract text.")





